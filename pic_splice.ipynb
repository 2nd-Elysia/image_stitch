{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import PIL\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 特征提取\n",
    "def extract_features(image):\n",
    "    feature_extractor = cv2.SIFT_create(nfeatures=10000, nOctaveLayers=4, contrastThreshold=0.02, edgeThreshold=10, sigma=1.0)\n",
    "    keypoints, descriptors = feature_extractor.detectAndCompute(image, None)\n",
    "    return keypoints, descriptors\n",
    "\n",
    "# 2. 特征匹配\n",
    "def match_features(descriptors1, descriptors2):\n",
    "    bf = cv2.BFMatcher()\n",
    "    matches = bf.knnMatch(descriptors1, descriptors2, k=2)\n",
    "    good_matches = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < 0.5 * n.distance:\n",
    "            good_matches.append(m)\n",
    "    return good_matches\n",
    "\n",
    "# 3. 变换估计\n",
    "def estimate_transform(keypoints1, keypoints2, good_matches):\n",
    "    src_pts = np.float32([keypoints1[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "    dst_pts = np.float32([keypoints2[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "    # 使用RANSAC算法估计变换矩阵\n",
    "    M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "    return M\n",
    "\n",
    "# 4. 变换应用并进行图像拼接\n",
    "# 4. 变换应用并进行图像拼接\n",
    "def stitch_images(image1, image2):\n",
    "    keypoints1, descriptors1 = extract_features(image1)\n",
    "    keypoints2, descriptors2 = extract_features(image2)\n",
    "\n",
    "    good_matches = match_features(descriptors1, descriptors2)\n",
    "    M = estimate_transform(keypoints1, keypoints2, good_matches)\n",
    "\n",
    "    h1, w1 = image1.shape\n",
    "    h2, w2 = image2.shape\n",
    "    new_height = max(h1, h2)\n",
    "    new_width = w1 + w2\n",
    "\n",
    "    # 创建一个空白的拼接图像\n",
    "    stitched_image = np.zeros((new_height, new_width), dtype=np.uint8)\n",
    "\n",
    "    # 应用变换到第一幅图像\n",
    "    transformed_image = cv2.warpPerspective(image1, M, (new_width, new_height))\n",
    "\n",
    "    # 将第一幅图像复制到拼接图像的左侧\n",
    "    stitched_image[:, :w1] = transformed_image\n",
    "\n",
    "    # 将第二幅图像复制到拼接图像的右侧\n",
    "    stitched_image[:, w1:] = image2\n",
    "\n",
    "    return stitched_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (3036,8048) into shape (3036,4024)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\桌面\\Image_registration\\pic_splice.ipynb 单元格 3\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/%E6%A1%8C%E9%9D%A2/Image_registration/pic_splice.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39mlen\u001b[39m(image_paths)):\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/%E6%A1%8C%E9%9D%A2/Image_registration/pic_splice.ipynb#W4sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     next_image \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread(image_paths[i], cv2\u001b[39m.\u001b[39mIMREAD_GRAYSCALE)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/%E6%A1%8C%E9%9D%A2/Image_registration/pic_splice.ipynb#W4sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     stitched_image \u001b[39m=\u001b[39m stitch_images(stitched_image, next_image)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/%E6%A1%8C%E9%9D%A2/Image_registration/pic_splice.ipynb#W4sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# 保存拼接后的图像\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%E6%A1%8C%E9%9D%A2/Image_registration/pic_splice.ipynb#W4sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m cv2\u001b[39m.\u001b[39mimwrite(\u001b[39m'\u001b[39m\u001b[39mpanorama_image.png\u001b[39m\u001b[39m'\u001b[39m, stitched_image)\n",
      "\u001b[1;32md:\\桌面\\Image_registration\\pic_splice.ipynb 单元格 3\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%E6%A1%8C%E9%9D%A2/Image_registration/pic_splice.ipynb#W4sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m transformed_image \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mwarpPerspective(image1, M, (new_width, new_height))\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%E6%A1%8C%E9%9D%A2/Image_registration/pic_splice.ipynb#W4sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39m# 将第一幅图像复制到拼接图像的左侧\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/%E6%A1%8C%E9%9D%A2/Image_registration/pic_splice.ipynb#W4sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m stitched_image[:, :w1] \u001b[39m=\u001b[39m transformed_image\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%E6%A1%8C%E9%9D%A2/Image_registration/pic_splice.ipynb#W4sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m \u001b[39m# 将第二幅图像复制到拼接图像的右侧\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%E6%A1%8C%E9%9D%A2/Image_registration/pic_splice.ipynb#W4sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m stitched_image[:, w1:] \u001b[39m=\u001b[39m image2\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (3036,8048) into shape (3036,4024)"
     ]
    }
   ],
   "source": [
    "# 读取多幅图像\n",
    "image_paths = ['origin_images/2.png', 'origin_images/222.png']\n",
    "stitched_image = cv2.imread(image_paths[0], cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "for i in range(1, len(image_paths)):\n",
    "    next_image = cv2.imread(image_paths[i], cv2.IMREAD_GRAYSCALE)\n",
    "    stitched_image = stitch_images(stitched_image, next_image)\n",
    "\n",
    "# 保存拼接后的图像\n",
    "cv2.imwrite('panorama_image.png', stitched_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3036, 4024, 3)\n"
     ]
    }
   ],
   "source": [
    "image2 = cv2.imread('origin_images/2.png')\n",
    "print(image2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "# 读取两张图像\n",
    "image1 = cv2.imread('origin_images/2.png')\n",
    "image2 = cv2.imread('origin_images/442.png')\n",
    "# 创建特征点检测器和描述子提取器\n",
    "# 修改ORB特征提取函数\n",
    "# 1. 特征提取\n",
    "def extract_features(image):\n",
    "    feature_extractor = cv2.SIFT_create(nfeatures=10000, nOctaveLayers=4, contrastThreshold=0.02, edgeThreshold=10, sigma=1.0)\n",
    "    keypoints, descriptors = feature_extractor.detectAndCompute(image, None)\n",
    "    return keypoints, descriptors\n",
    "def match_features(descriptors1, descriptors2):\n",
    "    bf = cv2.BFMatcher()\n",
    "    matches = bf.knnMatch(descriptors1, descriptors2, k=2)\n",
    "    good_matches = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < 0.5 * n.distance:\n",
    "            good_matches.append(m)\n",
    "    return good_matches\n",
    "\n",
    "# 对image1和image2分别应用ORB特征提取\n",
    "keypoints1, descriptors1 = extract_features(image1)\n",
    "keypoints2, descriptors2 = extract_features(image2)\n",
    "# 使用BFMatcher进行特征点匹配\n",
    "matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "good_matches = match_features(descriptors1, descriptors2)\n",
    "\n",
    "# 提取匹配点对应的特征点坐标\n",
    "points1 = np.float32([keypoints1[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "points2 = np.float32([keypoints2[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "# 使用RANSAC算法估计两张图像之间的透视变换矩阵\n",
    "M, _ = cv2.findHomography(points1, points2, cv2.RANSAC, 5.0)\n",
    "# 对图像1进行透视变换，将其拼接到图像2上\n",
    "result = cv2.warpPerspective(image1, M, (image1.shape[1] + image2.shape[1], image2.shape[0]))\n",
    "result[0:image2.shape[0], 0:image2.shape[1]] = image2\n",
    "# 显示拼接结果\n",
    "# cv2.imshow('Image Stitching', result)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "cv2.imwrite(\"panorama_image.png\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\core\\src\\count_non_zero.dispatch.cpp:124: error: (-215:Assertion failed) cn == 1 in function 'cv::countNonZero'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32md:\\桌面\\Image_registration\\pic_splice.ipynb 单元格 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/%E6%A1%8C%E9%9D%A2/Image_registration/pic_splice.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m zero_pixel_count \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39msize \u001b[39m-\u001b[39m cv2\u001b[39m.\u001b[39;49mcountNonZero(result)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/%E6%A1%8C%E9%9D%A2/Image_registration/pic_splice.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m像素值为0的点的数量：\u001b[39m\u001b[39m\"\u001b[39m, zero_pixel_count)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/%E6%A1%8C%E9%9D%A2/Image_registration/pic_splice.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m像素为0的点的占比 ：\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m(zero_pixel_count\u001b[39m/\u001b[39mresult\u001b[39m.\u001b[39msize)\u001b[39m \u001b[39m\u001b[39m:\u001b[39;00m\u001b[39m.2%\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.8.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\core\\src\\count_non_zero.dispatch.cpp:124: error: (-215:Assertion failed) cn == 1 in function 'cv::countNonZero'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "zero_pixel_count = result.size - cv2.countNonZero(result)\n",
    "print(\"像素值为0的点的数量：\", zero_pixel_count)\n",
    "print(\"像素为0的点的占比 ：\",f'{(zero_pixel_count/result.size) :.2%}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
